---
slug: master-slave-archiecture
title: Master Slave Archiecture
readTime: 20 min
orderIndex: 3
premium: false
---





Master-Slave Architecture: The Classic Database Pattern (Now Called Primary-Replica)
ğŸ¯ Challenge 1: The Single Chef Kitchen Problem
Imagine this scenario: You run a restaurant with one chef who does everything.

Single Chef (No Delegation):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Single Chef                 â”‚
â”‚                                      â”‚
â”‚  - Takes orders from customers       â”‚
â”‚  - Prepares all dishes              â”‚
â”‚  - Answers recipe questions         â”‚
â”‚  - Trains new staff                 â”‚
â”‚  - Everything!                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problems:
âŒ Chef overwhelmed (handles everything)
âŒ Long wait times (bottleneck)
âŒ Chef sick = Restaurant closed! (single point of failure)
âŒ Can't scale (only one chef can fit in kitchen)
âŒ Customers far away wait longer (latency)
```

Head Chef + Sous Chefs (Master-Slave Pattern):
```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Head Chef        â”‚ â† Creates new recipes (WRITES)
          â”‚    (Master/Primary) â”‚    Updates menu
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Trains others
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“           â†“           â†“          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Sous    â”‚ â”‚ Sous    â”‚ â”‚ Sous    â”‚ â”‚ Sous    â”‚
    â”‚ Chef 1  â”‚ â”‚ Chef 2  â”‚ â”‚ Chef 3  â”‚ â”‚ Chef 4  â”‚
    â”‚ (Slave) â”‚ â”‚ (Slave) â”‚ â”‚ (Slave) â”‚ â”‚ (Slave) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    Answers      Answers      Answers      Answers
    customer     customer     customer     customer
    questions    questions    questions    questions
    (READS)      (READS)      (READS)      (READS)

Flow:
1. Head Chef creates new recipe â†’ Teaches all Sous Chefs
2. Customers ask about recipes â†’ Any Sous Chef can answer
3. Menu change needed â†’ Only Head Chef can do it
4. Head Chef busy/sick â†’ Promote a Sous Chef to Head Chef

Benefits:
âœ… Head Chef focuses on important work (writes)
âœ… Customers get fast answers (reads from nearest Sous Chef)
âœ… Many Sous Chefs = handle many customers (scalability)
âœ… Head Chef leaves â†’ Sous Chef promoted (high availability)
âœ… Sous Chefs in different locations (global distribution)
```

Pause and think: What if your database had one server for writes and many servers for reads?

The Answer: Master-Slave architecture (now called Primary-Replica) separates write and read responsibilities! It's like:
âœ… Master/Primary = Single source of truth (handles all writes)
âœ… Slaves/Replicas = Copies that follow master (handle reads)
âœ… Data flows one direction (master â†’ slaves)
âœ… Automatic promotion on failure (slave becomes master)
âœ… Read scalability (add more slaves = more read capacity)

**Terminology Note:** The industry is transitioning from "Master-Slave" to "Primary-Replica" for inclusivity. They mean the same thing. Modern documentation uses Primary-Replica.

Key Insight: This pattern trades write scalability for read scalability - you can't scale writes, but you can scale reads infinitely!

ğŸ¬ Interactive Exercise: Write vs Read Workloads

Understanding the 90/10 Rule:
```
Most applications are read-heavy:

Typical Web Application:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 90% Reads (SELECT)             â”‚ â† Can go to replicas!
â”‚ - View user profile            â”‚
â”‚ - Browse products              â”‚
â”‚ - Check order status           â”‚
â”‚ - View comments                â”‚
â”‚ - Load dashboard               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 10% Writes (INSERT/UPDATE)     â”‚ â† Must go to primary!
â”‚ - Create account               â”‚
â”‚ - Update profile               â”‚
â”‚ - Place order                  â”‚
â”‚ - Post comment                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

With Primary-Replica:
- 10% traffic â†’ Primary (manageable!)
- 90% traffic â†’ Distributed across replicas (scales!)
```

Single Database (No Replication):
```
All Traffic â†’ Single Database

With 1000 requests/second:
â”œâ”€ 900 reads/sec
â””â”€ 100 writes/sec

Single database handles:
1000 total requests/sec âš ï¸ (struggling)

Scaling option: Bigger server ğŸ’° (expensive!)
```

Primary-Replica (With Replication):
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Primary    â”‚ â† 100 writes/sec (10%)
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“          â†“          â†“          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Replicaâ”‚â”‚Replicaâ”‚â”‚Replicaâ”‚â”‚Replicaâ”‚
â”‚   1   â”‚â”‚   2   â”‚â”‚   3   â”‚â”‚   4   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  225        225        225        225
reads/sec reads/sec reads/sec reads/sec

Primary handles: 100 writes/sec (easy! âœ“)
Each replica handles: 225 reads/sec (easy! âœ“)
Total capacity: 1000 requests/sec (distributed!)

Need more capacity? Add more replicas!
```

The Math:
```
Without Replication:
1 server handling 1000 req/sec = stressed
Solution: Upgrade to massive server = expensive

With Replication (1 primary + 4 replicas):
Primary: 100 req/sec (10% of total)
Each replica: 225 req/sec (22.5% of reads)
5 commodity servers = cheaper + more scalable

To double capacity:
- Add 4 more replicas (8 total)
- Each now handles ~112 reads/sec
- Linear scaling! âœ“
```

Real-world parallel: Primary-Replica is like a company with one CEO (makes decisions) and many managers (answer questions). CEO isn't overwhelmed because managers handle most inquiries.

ğŸ—ï¸ How Primary-Replica Works (The Details)

The Write Path:
```
Step 1: Client sends write
Client: UPDATE users SET email='new@email.com' WHERE id=123;
   â†“
Step 2: Primary receives and executes
Primary: Executes UPDATE on local database
Primary: Data changed: user 123 email updated âœ“
   â†“
Step 3: Primary logs change
Primary: Writes to binlog/WAL (write-ahead log)
Entry: "user 123 email changed to new@email.com"
   â†“
Step 4: Primary sends to replicas
Primary â†’ Replica 1: "Apply this change"
Primary â†’ Replica 2: "Apply this change"
Primary â†’ Replica 3: "Apply this change"
   â†“
Step 5: Replicas apply change
Replica 1: Executes UPDATE âœ“
Replica 2: Executes UPDATE âœ“
Replica 3: Executes UPDATE âœ“
   â†“
Step 6: (Optional) Replicas acknowledge
Replica 1 â†’ Primary: "Done!"
Replica 2 â†’ Primary: "Done!"
Replica 3 â†’ Primary: "Done!"
   â†“
Step 7: Primary returns to client
Primary â†’ Client: "UPDATE successful!" âœ“

Total time: ~50-200ms (depending on synchronous vs async)
```

The Read Path:
```
Option A: Read from Primary
Client: SELECT * FROM users WHERE id=123;
   â†“
Primary: Returns data âœ“
   â†“
Client: Gets response (10ms)

Pros: Always latest data
Cons: Primary handles read load too

Option B: Read from Replica (Common)
Client: SELECT * FROM users WHERE id=123;
   â†“
Replica 2: Returns data âœ“
   â†“
Client: Gets response (10ms)

Pros: Offloads primary, scalable
Cons: Might be slightly stale (replication lag)
```

Replication Modes:

Asynchronous (Default):
```
Client â†’ Primary: UPDATE user 123
           â†“
Primary: Execute UPDATE
           â†“
Primary â†’ Client: "Success!" âœ“ (returns immediately)
           â†“
           (Async) Send to replicas in background
           â†“
Replicas: Apply change (few milliseconds later)

Pros:
âœ… Fast writes (don't wait for replicas)
âœ… Primary not blocked if replica is down

Cons:
âŒ If primary crashes before replication, some writes lost!
âŒ Replicas lag behind (eventual consistency)
```

Synchronous:
```
Client â†’ Primary: UPDATE user 123
           â†“
Primary: Execute UPDATE
           â†“
Primary â†’ Replicas: Send change
           â†“
Wait for replicas to confirm...
           â†“
Replica 1: "Applied!" âœ“
Replica 2: "Applied!" âœ“
           â†“
Primary â†’ Client: "Success!" âœ“

Pros:
âœ… No data loss (replicas guaranteed to have data)
âœ… Read from replica = guaranteed fresh

Cons:
âŒ Slower writes (wait for network round-trip)
âŒ If all replicas down, primary blocks writes!
```

Semi-synchronous (Best of Both):
```
Primary waits for at least 1 replica (not all):

Client â†’ Primary: UPDATE user 123
           â†“
Primary: Execute UPDATE
           â†“
Primary â†’ All Replicas: Send change
           â†“
Replica 1: "Applied!" âœ“ (fastest replica)
           â†“
Primary â†’ Client: "Success!" âœ“ (doesn't wait for others)
           â†“
Replica 2: "Applied!" âœ“ (slower, in background)
Replica 3: "Applied!" âœ“

Pros:
âœ… Fast enough (wait for 1 replica, not all)
âœ… Data safe (at least 1 replica confirmed)
âœ… If fastest replica down, waits for another

Balanced approach! âš–ï¸
```

Real-world parallel:
- Async = Mail drop box (drop and go, delivered later)
- Synchronous = Certified mail (wait for signature)
- Semi-sync = Quick signature from receptionist (fast but confirmed)

ğŸ® Decision Game: Which Replication Mode?

Context: You're configuring replication. Which mode should you use?

Scenarios:
A. Social media likes counter
B. Bank account balance
C. Blog post content
D. Shopping cart contents
E. User session data
F. Financial transaction log
G. Product catalog
H. Real-time analytics dashboard

Options:
1. Asynchronous (fast, might lose recent writes)
2. Semi-synchronous (balanced)
3. Synchronous (slow, no data loss)

Think about: Can you afford to lose data? Need fast writes?

Answers:
```
A. Social likes â†’ Asynchronous (1)
   Reason: Losing a few likes acceptable, need fast

B. Bank balance â†’ Synchronous (3)
   Reason: Cannot lose money data!

C. Blog posts â†’ Semi-synchronous (2)
   Reason: Important but not critical, balanced

D. Shopping cart â†’ Asynchronous (1)
   Reason: Temporary data, can reconstruct

E. User session â†’ Asynchronous (1)
   Reason: OK if user re-logs in

F. Financial log â†’ Synchronous (3)
   Reason: Audit trail, cannot lose

G. Product catalog â†’ Semi-synchronous (2)
   Reason: Important but doesn't change often

H. Analytics â†’ Asynchronous (1)
   Reason: Approximate data OK, need speed
```

Configuration Examples:
```sql
-- MySQL: Semi-synchronous replication
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
SET GLOBAL rpl_semi_sync_master_enabled = 1;
SET GLOBAL rpl_semi_sync_master_timeout = 1000; -- 1 second

-- PostgreSQL: Synchronous replication
-- postgresql.conf
synchronous_commit = remote_apply
synchronous_standby_names = 'replica1,replica2'

-- MongoDB: Write concern
db.users.update(
  { _id: 123 },
  { $set: { email: 'new@example.com' } },
  { writeConcern: { w: "majority", j: true } }
)
```

ğŸš¨ Common Misconception: "Replicas Are Identical to Primary... Right?"

You might think: "Replica = exact copy at all times."

The Reality: Replicas are eventually consistent!

Replication Lag Scenario:
```
Time: 10:00:00.000
Primary: user.balance = $1000

Time: 10:00:00.010
Primary: UPDATE users SET balance = 900 WHERE id=123;
Primary: user.balance = $900 âœ“

Time: 10:00:00.015 (5ms later)
Replica 1: Still sees user.balance = $1000 âœ— (lagging!)

Time: 10:00:00.050 (40ms later)
Replica 1: user.balance = $900 âœ“ (caught up!)

During this 40ms window:
- Read from Primary: $900 âœ“
- Read from Replica 1: $1000 âœ— (stale!)
```

Real-World Bug:
```python
# User withdraws money
def withdraw(user_id, amount):
    # Write to primary
    primary_db.execute(
        "UPDATE accounts SET balance = balance - %s WHERE id = %s",
        (amount, user_id)
    )

    # Redirect to account page
    return redirect('/account')

def account_page(user_id):
    # Reads from replica (for performance)
    account = replica_db.execute(
        "SELECT balance FROM accounts WHERE id = %s",
        (user_id,)
    ).fetchone()

    return f"Your balance: ${account.balance}"

# Bug!
# 1. User withdraws $100
# 2. Primary updated: balance = $900
# 3. Page redirects to /account
# 4. Reads from replica (not yet updated): balance = $1000
# 5. User sees old balance! "Withdrawal didn't work!"
```

Solutions:

Solution 1: Read Your Own Writes
```python
def withdraw(user_id, amount):
    primary_db.execute(...)

    # Store that this user should read from primary temporarily
    cache.set(f"read_from_primary:{user_id}", True, timeout=5)

    return redirect('/account')

def account_page(user_id):
    # Check if user needs primary reads
    if cache.get(f"read_from_primary:{user_id}"):
        account = primary_db.execute(...).fetchone()
    else:
        account = replica_db.execute(...).fetchone()

    return f"Your balance: ${account.balance}"
```

Solution 2: Sticky Sessions to Primary
```python
# Route user to primary for N seconds after write
session['route_to_primary_until'] = time.time() + 5

def get_db(session):
    if time.time() < session.get('route_to_primary_until', 0):
        return primary_db
    return replica_db
```

Solution 3: Check Replication Position
```python
def withdraw(user_id, amount):
    primary_db.execute(...)

    # Get current replication position
    position = primary_db.execute("SELECT pg_current_wal_lsn()").fetchone()
    session['min_replication_position'] = position

def account_page(user_id):
    min_pos = session.get('min_replication_position')

    # Find replica that's caught up
    for replica in replicas:
        replica_pos = replica.execute("SELECT pg_last_wal_replay_lsn()").fetchone()
        if replica_pos >= min_pos:
            return replica.execute(...).fetchone()

    # All replicas lagging, use primary
    return primary_db.execute(...).fetchone()
```

Real-world parallel: Replication lag is like news propagation. Breaking news (primary) takes time to reach newspapers (replicas).

âš¡ Failover: Promoting a Replica to Primary

Automatic Failover Flow:
```
Normal State:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary â”‚â”€â”€â”€â”€â†’â”‚Replica 1â”‚â”€â”€â”€â”€â†’â”‚Replica 2â”‚
â”‚ Server Aâ”‚     â”‚ Server Bâ”‚     â”‚ Server Câ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
  All writes

Primary Crashes! ğŸ’¥
     â†“
Step 1: Detection (10 seconds)
Health checks fail
Monitoring: "Primary is down!"
     â†“
Step 2: Choose new primary
Algorithm: Pick most up-to-date replica
Winner: Replica 1 (has most recent data)
     â†“
Step 3: Promote Replica 1
Replica 1: Becomes new primary
Replica 1: Stops following old primary
Replica 1: Starts accepting writes
     â†“
Step 4: Reconfigure other replicas
Replica 2: Now follows Replica 1 (new primary)
     â†“
Step 5: Update connection strings
DNS/Load Balancer: Points to new primary
Apps reconnect to new primary
     â†“
New State:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PRIMARY â”‚â”€â”€â”€â”€â†’â”‚Replica 2â”‚
â”‚(was Rep1)â”‚     â”‚ Server Câ”‚
â”‚ Server Bâ”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚
  All writes

Total downtime: 30-60 seconds
```

When Old Primary Returns:
```
Old Primary (Server A) comes back online:
     â†“
Option 1: Becomes replica
- Server A: Rewinds to divergence point
- Server A: Follows new primary (Server B)
- Now have 2 replicas again âœ“

Option 2: Manual recovery
- DBA inspects for split-brain
- Manually reconfigures
- Safer but requires human intervention
```

Split-Brain Prevention:
```
Dangerous scenario:
Both old and new primary accept writes!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Old     â”‚                    â”‚ New     â”‚
â”‚ Primary â”‚ Network partition! â”‚ Primary â”‚
â”‚         â”‚â†â”€â”€â”€â”€â”€â”€âœ—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚         â”‚
â”‚ Server Aâ”‚                    â”‚ Server Bâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                              â”‚
 App 1 writes here            App 2 writes here

Data diverges! This is SPLIT-BRAIN! âœ—

Prevention:
- Use quorum (need majority of nodes agreement)
- Fencing (shut down old primary forcefully)
- Distributed consensus (Raft, Paxos)
```

Tools for Automatic Failover:

MySQL with MHA (Master High Availability):
```bash
# MHA monitors primary health
# Automatically promotes replica on failure

# Configuration
cat /etc/mha/app1.cnf
[server default]
master_ip_failover_script=/usr/local/bin/master_ip_failover

[server1]
hostname=primary.db
candidate_master=1

[server2]
hostname=replica1.db
candidate_master=1

[server3]
hostname=replica2.db
no_master=1

# Run MHA manager
nohup masterha_manager --conf=/etc/mha/app1.cnf &

# When primary fails:
# 1. MHA detects failure
# 2. Promotes best replica
# 3. Reconfigures other replicas
# 4. Executes IP failover script
# 5. Updates DNS/VIP
```

PostgreSQL with Patroni:
```yaml
# patroni.yml
scope: postgres-ha
name: node1

bootstrap:
  dcs:
    ttl: 30
    loop_wait: 10
    maximum_lag_on_failover: 1048576

# Patroni uses etcd/Consul/Zookeeper for coordination
# Automatic leader election
# No manual intervention needed!

# Check cluster status
patronictl -c patroni.yml list

+ Cluster: postgres-ha (123456) -------+----+-----------+
| Member | Host      | Role    | State  | Lag in MB |
+--------+-----------+---------+--------+-----------+
| node1  | 10.0.0.1  | Leader  | running|         0 |
| node2  | 10.0.0.2  | Replica | running|         0 |
| node3  | 10.0.0.3  | Replica | running|         0 |
+--------+-----------+---------+--------+-----------+
```

Real-world parallel: Automatic failover is like a monarchy with clear succession rules. When king dies, crown prince automatically becomes king.

ğŸ’¡ Read-Write Splitting in Application

Application Pattern:
```python
class DatabaseRouter:
    def __init__(self):
        self.primary = connect('postgresql://primary:5432/db')
        self.replicas = [
            connect('postgresql://replica1:5432/db'),
            connect('postgresql://replica2:5432/db'),
            connect('postgresql://replica3:5432/db'),
        ]
        self.replica_index = 0

    def execute_write(self, query, params):
        """All writes go to primary"""
        return self.primary.execute(query, params)

    def execute_read(self, query, params):
        """Reads go to replicas (round-robin)"""
        replica = self.replicas[self.replica_index]
        self.replica_index = (self.replica_index + 1) % len(self.replicas)
        return replica.execute(query, params)

# Usage
db = DatabaseRouter()

# Write operations
db.execute_write(
    "INSERT INTO users (name, email) VALUES (%s, %s)",
    ("Alice", "alice@example.com")
)

# Read operations
users = db.execute_read(
    "SELECT * FROM users WHERE active = %s",
    (True,)
)
```

Django Database Router:
```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'HOST': 'primary.db',
    },
    'replica1': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'HOST': 'replica1.db',
    },
    'replica2': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'mydb',
        'HOST': 'replica2.db',
    },
}

# database_router.py
class PrimaryReplicaRouter:
    def db_for_read(self, model, **hints):
        """Reads go to replicas"""
        return random.choice(['replica1', 'replica2'])

    def db_for_write(self, model, **hints):
        """Writes go to primary"""
        return 'default'

# settings.py
DATABASE_ROUTERS = ['myapp.database_router.PrimaryReplicaRouter']

# Now all .save() goes to primary
# All .get() and .filter() go to replicas!
user = User.objects.get(id=123)  # Reads from replica
user.email = 'new@example.com'
user.save()  # Writes to primary
```

Real-world parallel: Read-write splitting is like having separate checkout (write) and browsing (read) in a store. Browsing happens anywhere, checkout at specific counter.

ğŸ’¡ Final Synthesis Challenge: The Organization Structure

Complete this comparison:
"A database without primary-replica is like a company with no delegation. A primary-replica database is like..."

Your answer should include:
- Write vs read separation
- Scalability benefits
- High availability
- Trade-offs

Take a moment to formulate your complete answer...

The Complete Picture:
A primary-replica database is like a well-organized company with clear delegation:

âœ… **Primary (CEO)**: Makes all decisions (writes), source of truth
âœ… **Replicas (Managers)**: Answer questions (reads), spread across locations
âœ… **Delegation**: CEO not overwhelmed (writes are minority of workload)
âœ… **Scalability**: Add more managers (replicas) = handle more inquiries (reads)
âœ… **Succession**: CEO leaves, VP promoted (automatic failover)
âœ… **Global presence**: Managers in each region (low latency reads worldwide)
âœ… **Eventually consistent**: New policy (write) takes time to reach all managers

**Benefits:**
1. **Read Scalability** - Add replicas = handle more read traffic
2. **High Availability** - Primary fails, promote replica
3. **Disaster Recovery** - Data exists on multiple servers
4. **Geographic Distribution** - Serve users from nearest replica
5. **Offload Primary** - Primary focuses on writes

**Trade-offs:**
- Replication lag (eventual consistency)
- Writes don't scale (still bottleneck on primary)
- More complex application code (read-write splitting)
- Split-brain risk (need proper failover)

**Real-world examples:**
- Reddit: Read replicas for comment browsing
- Stack Overflow: Replicas in multiple data centers
- WordPress.com: Read replicas for blog views
- Netflix: Replicas for catalog browsing

Primary-replica transforms single-server databases into scalable, highly available systems!

ğŸ¯ Quick Recap: Test Your Understanding
Without looking back, can you explain:
1. Why is it called primary-replica instead of master-slave now?
2. How does primary-replica handle read-heavy workloads?
3. What is replication lag and when does it matter?
4. How does automatic failover work?

Mental check: If you can design a primary-replica system, you understand the pattern!

ğŸš€ Your Next Learning Adventure
Now that you understand primary-replica, explore:

Advanced Topics:
- Multi-primary replication
- Cascading replication
- Delayed replicas (for recovery from mistakes)
- Logical replication

Replication Tools:
- ProxySQL (MySQL read-write splitting)
- PgBouncer (PostgreSQL connection pooling)
- HAProxy (database load balancing)
- Orchestrator (MySQL topology management)

Related Concepts:
- Database sharding
- Distributed databases
- CQRS (Command Query Responsibility Segregation)
- Event sourcing

Real-World Case Studies:
- How Wikipedia handles millions of readers
- GitHub's database architecture
- Instagram's replica lag handling
- Twitter's database evolution
