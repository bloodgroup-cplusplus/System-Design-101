---
slug: memory-hierarchy
title: Computer Memory Hierarchy
readTime: 20 min
orderIndex: 3
premium: false
---


## **ğŸ’¾ 3: Memory Hierarchy \- The Speed Pyramid**

Youâ€™ll learn more about storage in the â€œStorage Fundamentalsâ€**section of the content in following

### **ğŸ¯ Challenge 3: The Library Problem**

**Scenario:** You're writing a research paper. Where do you keep your materials?

**Option A:**

Everything in your brain (instant recall, tiny capacity)

**Option B:**

Books on your desk (quick to grab, limited space)

**Option C:**

Books on your bookshelf (walk to get them, more space)

**Option D:**

Books in the library (drive to get them, unlimited space)

**Question:**

Which do you use?

**The Answer:**

ALL OF THEM\! You use different storage based on frequency of access and size\!

**This is exactly how computer memory works\!**

---

### **ğŸ”ï¸ The Memory Pyramid**

THE MEMORY HIERARCHY
(Top \= Fastest/Smallest, Bottom \= Slowest/Largest)

![img12](https://res.cloudinary.com/dretwg3dy/image/upload/v1762355306/page35_gbmyot.png)

---

### **ğŸƒ Understanding the Speed Difference**

**Let's make these time scales relatable:**

LATENCY HUMANIZED:

If accessing a CPU register took 1 second:

L1 Cache:     3 seconds    (walk to next room)

L2 Cache:     14 seconds   (walk outside)

L3 Cache:     75 seconds   (drive to corner store)

RAM:          5 minutes    (drive across town)

SSD:          4 days       (fly to Europe)

HDD:          1 year       (travel to Saturn)

The difference is MASSIVE\!

---

### **ğŸ“š Detailed Look at Each Level**

#### **Level 1: CPU Registers**

ğŸ¯ REGISTERS \- The Brain's Scratchpad

Location: Inside the CPU itself

Size: \~16-32 registers Ã— 64 bits \= 100-200 bytes

Speed: 0.3 nanoseconds (one CPU cycle)

What they hold:

â”œâ”€ Currently executing instruction

â”œâ”€ Temporary calculation results

â”œâ”€ Memory addresses being accessed

â””â”€ Program counter (what to do next

![img13](https://res.cloudinary.com/dretwg3dy/image/upload/v1762355590/3_6_w565ib.png)


Think of it as: Calculator display showing current number

---

#### **Level 2: L1 Cache**

ğŸš€ L1 CACHE \- The CPU's Immediate Memory

Location: On the CPU chip, closest to cores
Size: 32-64 KB per core
Speed: 4 cycles (\~1 nanosecond)

Split into two parts:

â”œâ”€ L1 Instruction Cache (code being executed)

â””â”€ L1 Data Cache (data being processed)

Modern CPU (8 cores):
![img14](https://res.cloudinary.com/dretwg3dy/image/upload/v1762354297/22_aozppg.png)

Think of it as: Items on your desk within arm's reach

---

#### **Level 3: L2 Cache**

ğŸ’¨ L2 CACHE \- The CPU's Short-term Memory

Location: On CPU chip, still very close
Size: 256-512 KB per core
Speed: 12 cycles (\~3 nanoseconds)

Holds:

â”œâ”€ Recently used instructions and data

â”œâ”€ Data predicted to be used soon

â””â”€ Overflow from L1 cache

Modern CPU (8 cores):

![img15](https://res.cloudinary.com/dretwg3dy/image/upload/v1762355807/37_vxrhpt.png)

Think of it as: Drawer under your desk

---

#### **Level 4: L3 Cache**

âš¡ L3 CACHE \- Shared CPU Memory

Location: On CPU chip, shared by all cores
Size: 8-64 MB (entire chip)
Speed: 40 cycles (\~15 nanoseconds)

Shared resource:

![img16](https://res.cloudinary.com/dretwg3dy/image/upload/v1762354295/18_nz9ltg.png)

Benefits:

âœ“ Cores can share data efficiently

âœ“ Larger capacity

âœ“ Still much faster than RAM

Think of it as: Bookshelf in your office (shared)

---

#### **Level 5: RAM (Random Access Memory)**

ğŸ’¾ RAM \- Main System Memory

Location: Separate chips on motherboard
Size: 8-128 GB (typical systems)
Speed: 100 nanoseconds

What it holds:

â”œâ”€ Running applications

â”œâ”€ Operating system

â”œâ”€ Open documents

â”œâ”€ Browser tabs

â””â”€ Game data

Example system with 16GB RAM:

![img17](https://res.cloudinary.com/dretwg3dy/image/upload/v1762354296/15_sb6c2i.png)

Characteristics:

âœ“ Volatile (loses data when powered off)

âœ“ Much larger than cache

âœ“ 100x slower than L3 cache

âœ“ 1,000,000x faster than HDD

Think of it as: Your desk workspace

---

#### **Level 6: SSD (Solid State Drive)**

ğŸ’¿ SSD \- Fast Persistent Storage

Location: Connected via SATA/NVMe

Size: 256 GB \- 4 TB

Speed: 100 microseconds (100,000 nanoseconds)

What it holds:

â”œâ”€ Operating system files

â”œâ”€ Programs and applications

â”œâ”€ Documents, photos, videos

â””â”€ Game installations

Characteristics:

âœ“ Persistent (keeps data when off)

âœ“ 1000x slower than RAM

âœ“ No moving parts (silent, durable)

âœ“ More expensive per GB

Speed comparison to HDD:

![img18](https://res.cloudinary.com/dretwg3dy/image/upload/v1762354296/13_bwainy.png)

Think of it as: Filing cabinet with instant-access drawers

---

#### **Level 7: HDD (Hard Disk Drive)**

ğŸ’½ HDD \- Slow Mechanical Storage

Location: Connected via SATA
Size: 1-20 TB
Speed: 10 milliseconds (10,000,000 nanoseconds)

Physical structure:
![img19](https://res.cloudinary.com/dretwg3dy/image/upload/v1762354300/32_yns27w.png)

Characteristics:

âœ“ Persistent

âœ“ Very slow (moving parts\!)

âœ“ 100,000x slower than RAM

âœ“ Cheap per GB

âœ“ Large capacity

âœ“ Makes noise, uses power

âœ“ Fragile (hates drops\!)

Think of it as: Warehouse storage (takes time to retrieve)

---

### **ğŸ® Interactive Journey: The Cache Hunt**

**Let's follow what happens when the CPU needs data:**

THE DATA RETRIEVAL JOURNEY

CPU needs value at memory address 0x1234:

Step 1: Check L1 Cache
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CPU: "Is address 0x1234 in L1?"
L1: "Checking... NO\!" âŒ
Time wasted: 1 nanosecond
Status: L1 CACHE MISS

Step 2: Check L2 Cache
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CPU: "Is address 0x1234 in L2?"
L2: "Checking... NO\!" âŒ
Time wasted: 3 nanoseconds (total: 4ns)
Status: L2 CACHE MISS

Step 3: Check L3 Cache
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CPU: "Is address 0x1234 in L3?"
L3: "Checking... NO\!" âŒ
Time wasted: 15 nanoseconds (total: 19ns)
Status: L3 CACHE MISS

Step 4: Check RAM
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CPU: "Is address 0x1234 in RAM?"
RAM: "Found it\! Here's the value: 42" âœ“
Time taken: 100 nanoseconds (total: 119ns)
Status: RAM HIT

Step 5: Update Caches (for next time)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Copy value to L3: Address 0x1234 \= 42
Copy value to L2: Address 0x1234 \= 42
Copy value to L1: Address 0x1234 \= 42

Next time CPU needs 0x1234:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CPU: "Is address 0x1234 in L1?"
L1: "YES\! Value \= 42" âœ“
Time taken: 1 nanosecond

119x faster the second time\! ğŸš€

---

### **ğŸ“Š Cache Hit Rates: Why They Matter**

CACHE PERFORMANCE

Typical cache hit rates:
L1 Cache: 95% hit rate
L2 Cache: 80% hit rate (of L1 misses)
L3 Cache: 70% hit rate (of L2 misses)

Example with 1000 memory accesses:

950 found in L1 (1 ns each)
  \= 950 ns

40 found in L2 (3 ns each)
  \= 120 ns

21 found in L3 (15 ns each)
  \= 315 ns

10 found in RAM (100 ns each)
  \= 1000 ns

Total: 2,385 ns for 1000 accesses
Average: 2.4 ns per access\!

Without caches (all from RAM):
1000 Ã— 100 ns \= 100,000 ns

CACHE MAKES IT 42x FASTER\! ğŸš€

---

### **ğŸš¨ Common Misconception: "More Cache Always Better"**

**You might think:** "I want 1GB of L1 cache\!"

**The Reality:** Cache size is a careful balance\!

âŒ WHY YOU CAN'T HAVE HUGE CACHES:

Problem 1: PHYSICAL SPACE

â”œâ”€ Caches are on the CPU disk

â”œâ”€ Disc size is limited

â””â”€ Larger cache \= less room for cores

Problem 2: SPEED TRADEOFF

â”œâ”€ Larger cache \= more area to search

â”œâ”€ More area \= longer wires

â””â”€ Longer wires \= SLOWER access\!

Problem 3: COST
â”œâ”€ Cache memory is extremely expensive
â”œâ”€ L1 cache: $1000+ per MB\!
â””â”€ RAM: $5 per GB (200,000x cheaper\!)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… ACTUAL DESIGN:

Modern CPUs use optimal sizes:

L1: 32-64 KB (tiny but INSTANT)

L2: 256-512 KB (small but very fast)

L3: 8-64 MB (larger, shared, still fast)

RAM: 8-128 GB (huge, slower)

Each level is the sweet spot for its purpose\!

**The Engineering Tradeoff:**

Hypothetical 1MB L1 Cache:

âœ“ More hits

âœ“ More data stored

âœ— 10x slower access (defeats the purpose\!)

âœ— Takes up space for 2 CPU cores

âœ— Costs thousands of dollars

Actual 32KB L1 Cache:

âœ“ Lightning fast (0.3ns)

âœ“ Affordable

âœ“ Small enough to keep close to core

âœ“ High enough hit rate (95%)

Result: Small but fast beats large but slow\!

---

### **ğŸ¯ Memory Hierarchy Summary**

THE COMPLETE PICTURE:

Why this hierarchy exists:

ğŸƒ FAST \+ SMALL \+ EXPENSIVE

   â†•ï¸ Registers: Instant but microscopic

   â†•ï¸ L1 Cache: Nearly instant, tiny

   â†•ï¸ L2 Cache: Very fast, small

   â†•ï¸ L3 Cache: Fast, medium

ğŸ¢ SLOW \+ LARGE \+ CHEAP

   â†•ï¸ RAM: Decent, large

   â†•ï¸ SSD: Slow, huge

   â†•ï¸ HDD: Very slow, massive

The Principle: Keep frequently used data close\!

LOCALITY OF REFERENCE:

Temporal locality:

"If I accessed this data, I'll likely access it again soon"
â†’ Keep recent data in cache

Spatial locality:

"If I accessed this data, I'll likely access nearby data"

â†’ Load whole cache lines (64 bytes at a time)

This is why caches work so well\!
